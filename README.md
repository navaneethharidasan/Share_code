# Share_code
Public Sharing

The jupyter notebook GD_variants.ipynb compares following optimization methods with stochastic gradient descent (SGD):
(i)  SGD with momentum
(ii) RMSprop
(iii)ADAptive Momentum optimization (ADAM)